- en: P44ï¼šTalk James Bennett - A ğŸ's guide to Unicode - ç¨‹åºå‘˜ç™¾ç§‘ä¹¦ - BV1rW4y1v7YG
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P44ï¼šæ¼”è®²è€…è©¹å§†æ–¯Â·è´å†…ç‰¹ - ä¸€æ¡ğŸçš„UnicodeæŒ‡å— - ç¨‹åºå‘˜ç™¾ç§‘ä¹¦ - BV1rW4y1v7YG
- en: Hiï¼Œ I'm James and I'm here today to talk to you about Unicodeã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯è©¹å§†æ–¯ï¼Œä»Šå¤©æˆ‘æ¥å’Œä½ ä»¬è°ˆè°ˆUnicodeã€‚
- en: '![](img/2a3245dcd9af276985281a539c729f78_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_1.png)'
- en: Now I know that word can provoke some reactions in peopleï¼Œ so the very first
    thing I wantã€‚ to do is remind you of a wise message from a beloved modern philosopherã€‚
    Because Unicode is complex and I'm sure you've heard scary stories about itï¼Œ but
    it's notã€‚ something that you have to be afraid of and by the end of this talk
    I hope you won't beã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çŸ¥é“è¿™ä¸ªè¯å¯èƒ½ä¼šå¼•å‘ä¸€äº›ååº”ï¼Œæ‰€ä»¥æˆ‘æƒ³åšçš„ç¬¬ä¸€ä»¶äº‹å°±æ˜¯æé†’ä½ ä¸€å¥æ¥è‡ªå—äººå–œçˆ±çš„ç°ä»£å“²å­¦å®¶çš„æ™ºæ…§ä¿¡æ¯ã€‚å› ä¸ºUnicodeæ˜¯å¤æ‚çš„ï¼Œæˆ‘ç›¸ä¿¡ä½ å¬è¿‡å…³äºå®ƒçš„å¯æ€•æ•…äº‹ï¼Œä½†å®ƒå¹¶ä¸æ˜¯ä½ å¿…é¡»å®³æ€•çš„ä¸œè¥¿ã€‚å¸Œæœ›åœ¨è¿™ä¸ªæ¼”è®²ç»“æŸæ—¶ï¼Œä½ ä¸ä¼šå†å®³æ€•å®ƒã€‚
- en: afraid of itã€‚ Because you're going to understand where Unicode came fromã€‚ what
    it is and how it really worksï¼Œ how it gets implemented in computer systems and
    especially programming languages likeã€‚ Python and how you can work with it and
    recognize where the complexity in it is found so thatã€‚ you can manage that complexity
    and write more effective and more confident code so that youã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å¿…å®³æ€•å®ƒã€‚å› ä¸ºä½ å°†ç†è§£Unicodeçš„æ¥æºã€å®ƒæ˜¯ä»€ä¹ˆä»¥åŠå®ƒå¦‚ä½•çœŸæ­£è¿ä½œï¼Œå¦‚ä½•åœ¨è®¡ç®—æœºç³»ç»Ÿä¸­å®ç°ï¼Œç‰¹åˆ«æ˜¯åœ¨åƒPythonè¿™æ ·çš„ç¼–ç¨‹è¯­è¨€ä¸­ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒå¹¶è¯†åˆ«å…¶ä¸­çš„å¤æ‚æ€§ï¼Œä»¥ä¾¿ç®¡ç†è¿™ç§å¤æ‚æ€§ï¼Œç¼–å†™æ›´æœ‰æ•ˆã€æ›´è‡ªä¿¡çš„ä»£ç ã€‚
- en: don't have to be afraid of Unicode anymoreã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¸å†éœ€è¦å®³æ€•Unicodeäº†ã€‚
- en: '![](img/2a3245dcd9af276985281a539c729f78_3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_3.png)'
- en: But of course we have to start somewhereï¼Œ which means starting at the beginningã€‚
    And the history of Unicode really is the history of written textï¼Œ which is kind
    of complicatedã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œæˆ‘ä»¬å¾—ä»æŸä¸ªåœ°æ–¹å¼€å§‹ï¼Œè¿™æ„å‘³ç€ä»å¤´å¼€å§‹ã€‚Unicodeçš„å†å²å®é™…ä¸Šå°±æ˜¯ä¹¦é¢æ–‡æœ¬çš„å†å²ï¼Œè¿™å¾ˆå¤æ‚ã€‚
- en: '![](img/2a3245dcd9af276985281a539c729f78_5.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_5.png)'
- en: Because we're still not sure entirely what that history looks likeã€‚ We know
    writing seems to have been invented independently multiple times throughout historyã€‚
    and over the thousands of years since then people have come up with almost an
    unbelievableã€‚ number of different ways of writing down their thoughts and wordsã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºæˆ‘ä»¬ä»ç„¶ä¸å®Œå…¨ç¡®å®šé‚£æ®µå†å²æ˜¯æ€æ ·çš„ã€‚æˆ‘ä»¬çŸ¥é“ï¼Œä¹¦å†™ä¼¼ä¹åœ¨å†å²ä¸Šå¤šæ¬¡ç‹¬ç«‹å‘æ˜ã€‚åœ¨æ­¤åçš„å‡ åƒå¹´é‡Œï¼Œäººä»¬æƒ³å‡ºäº†å‡ ä¹éš¾ä»¥ç½®ä¿¡çš„ä¸åŒæ–¹å¼æ¥è®°å½•ä»–ä»¬çš„æ€æƒ³å’Œè¯­è¨€ã€‚
- en: Writing you can think of as a basis for a writing system has probably been used
    at someï¼Œ pointã€‚ There are writing systems that are based on individual sounds
    or syllables or whole wordsï¼Œ or ideasã€‚ There are writing systems that are based
    on abstract representations of an ideaã€‚ There are writing systems that are based
    on the position of your mouth as you pronounceï¼Œ a soundã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æŠŠä¹¦å†™è§†ä¸ºä¹¦å†™ç³»ç»Ÿçš„åŸºç¡€ï¼Œè¿™åœ¨æŸä¸ªæ—¶åˆ»å¯èƒ½è¢«ä½¿ç”¨è¿‡ã€‚æœ‰äº›ä¹¦å†™ç³»ç»ŸåŸºäºå•ä¸ªå£°éŸ³ã€éŸ³èŠ‚ã€å®Œæ•´å•è¯æˆ–æ€æƒ³ã€‚æœ‰äº›ä¹¦å†™ç³»ç»ŸåŸºäºä¸€ä¸ªæ€æƒ³çš„æŠ½è±¡è¡¨ç°å½¢å¼ã€‚æœ‰äº›ä¹¦å†™ç³»ç»ŸåŸºäºä½ å‘éŸ³æ—¶å£è…”çš„ä½ç½®ã€‚
- en: Really anything you can imagineï¼Œ probably someone has come up withã€‚ And the
    history of text encompasses all of those thingsï¼Œ which can be pretty complicatedã€‚
    Now fortunately for this talk we really only need to talk about the last couple
    of centuriesã€‚ When we've tried to come up with systems for representing and transmitting
    text electronicallyã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä»»ä½•ä½ èƒ½æƒ³è±¡çš„ä¸œè¥¿ï¼Œå¯èƒ½æœ‰äººéƒ½æƒ³åˆ°äº†ã€‚æ–‡æœ¬çš„å†å²æ¶µç›–äº†æ‰€æœ‰è¿™äº›å†…å®¹ï¼Œè¿™å¯èƒ½ç›¸å½“å¤æ‚ã€‚å¹¸è¿çš„æ˜¯ï¼Œå¯¹äºè¿™ä¸ªæ¼”è®²ï¼Œæˆ‘ä»¬åªéœ€è¦è®¨è®ºè¿‡å»å‡ ä¸ªä¸–çºªã€‚å½“æˆ‘ä»¬å°è¯•è®¾è®¡ç”¨äºç”µå­è¡¨ç¤ºå’Œä¼ è¾“æ–‡æœ¬çš„ç³»ç»Ÿæ—¶ã€‚
- en: There are older systems for long distance transmissionã€‚ There are semaphore
    systems and flag codes and signal fires and many other systems thatã€‚ were really
    effectiveã€‚ But today we're mostly concerned with electronic or electromagnetic
    broadcast over a wire orã€‚ radio wavesã€‚ And we've probably all seen some examples
    of early attempts at thisã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰æ›´å¤è€çš„è¿œç¨‹ä¼ è¾“ç³»ç»Ÿã€‚æœ‰ä¿¡å·ç³»ç»Ÿã€æ——å¸œä»£ç ã€ä¿¡å·ç«ç„°å’Œè®¸å¤šå…¶ä»–æœ‰æ•ˆçš„ç³»ç»Ÿã€‚ä½†ä»Šå¤©æˆ‘ä»¬ä¸»è¦å…³å¿ƒçš„æ˜¯é€šè¿‡ç”µçº¿æˆ–æ— çº¿ç”µæ³¢è¿›è¡Œç”µå­æˆ–ç”µç£å¹¿æ’­ã€‚æˆ‘ä»¬å¯èƒ½éƒ½è§è¿‡ä¸€äº›æ—©æœŸå°è¯•çš„ä¾‹å­ã€‚
- en: '![](img/2a3245dcd9af276985281a539c729f78_7.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_7.png)'
- en: This is one a lot of people know is Morse codeï¼Œ which was developed for a telegraph
    systemã€‚ It's a variable width encoding uses binary alphabet of two charactersï¼Œ
    a dot and a dashã€‚ And there was a whole family of different telegraph codes with
    different principles and based onã€‚ different ideasã€‚ One of the more popular later
    on was ITAã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¾ˆå¤šäººæ‰€ç†ŸçŸ¥çš„æ‘©å°”æ–¯ç”µç ï¼Œä¸“ä¸ºç”µæŠ¥ç³»ç»Ÿå¼€å‘ã€‚å®ƒæ˜¯ä¸€ç§å¯å˜å®½åº¦ç¼–ç ï¼Œä½¿ç”¨ä¸¤ä¸ªå­—ç¬¦çš„äºŒè¿›åˆ¶å­—æ¯ï¼Œä¸€ä¸ªç‚¹å’Œä¸€ä¸ªç ´æŠ˜å·ã€‚è¿˜æœ‰ä¸€æ•´å¥—ä¸åŒåŸç†å’Œä¸åŒæƒ³æ³•çš„ç”µæŠ¥ç¼–ç ã€‚åæ¥æ¯”è¾ƒæµè¡Œçš„æ˜¯ITAã€‚
- en: which is a baudot code named after Emil Baudotï¼Œ whoã€‚ also gives us the baud
    as a unit of transmission rateã€‚ And baudot codes are kind of interesting because
    they introduced this concept of control charactersã€‚ If you look at thisï¼Œ it's
    a five bit binary codeã€‚ Normally these messages would be recorded by being punched
    as holes in a paper tapeã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªä»¥åŸƒç±³å°”Â·åšå¤šå‘½åçš„æ³¢é“ç¼–ç ï¼Œåšé“åŒæ—¶ä¹Ÿç»™æˆ‘ä»¬å¸¦æ¥äº†ä¼ è¾“é€Ÿç‡çš„æ³¢ç‰¹å•ä½ã€‚æ³¢é“ç¼–ç å¾ˆæœ‰è¶£ï¼Œå› ä¸ºå®ƒå¼•å…¥äº†æ§åˆ¶å­—ç¬¦çš„æ¦‚å¿µã€‚å¦‚æœä½ çœ‹è¿™ä¸ªï¼Œå®ƒæ˜¯ä¸€ä¸ªäº”ä½çš„äºŒè¿›åˆ¶ä»£ç ã€‚é€šå¸¸ï¼Œè¿™äº›æ¶ˆæ¯ä¼šé€šè¿‡åœ¨çº¸å¸¦ä¸Šæ‰“å­”è®°å½•ã€‚
- en: whichï¼Œ sounds like it should only be able to handle 32 charactersã€‚ That's two
    to the fifth powerã€‚ But here the capacity is over 60 characters because it uses
    a control character to switchã€‚ between two different alphabets of charactersã€‚
    These sorts of clever innovations let people do a lot of cool things with the
    telegraph systemã€‚ as it evolved and eventually developed into modern computer
    text encoding systemsï¼Œ manyã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å¬èµ·æ¥å®ƒåªèƒ½å¤„ç†32ä¸ªå­—ç¬¦ã€‚è¿™æ˜¯äºŒçš„äº”æ¬¡æ–¹ã€‚ä½†è¿™é‡Œçš„å®¹é‡è¶…è¿‡60ä¸ªå­—ç¬¦ï¼Œå› ä¸ºå®ƒä½¿ç”¨æ§åˆ¶å­—ç¬¦åœ¨ä¸¤ç§ä¸åŒå­—ç¬¦å­—æ¯ä¹‹é—´åˆ‡æ¢ã€‚è¿™ç±»èªæ˜çš„åˆ›æ–°ä½¿äººä»¬èƒ½åœ¨ç”µæŠ¥ç³»ç»Ÿçš„å‘å±•ä¸­åšè®¸å¤šé…·ç‚«çš„äº‹æƒ…ï¼Œæœ€ç»ˆæ¼”å˜ä¸ºç°ä»£è®¡ç®—æœºæ–‡æœ¬ç¼–ç ç³»ç»Ÿã€‚
- en: of which were heavily influenced by these telegraph codesã€‚ This of course is
    the 100 pound gorilla in the roomï¼Œ ASCIIï¼Œ which owes a lot to ITA2ã€‚ and the baudot
    family of telegraph codesã€‚ But ASCII really took over the world even though it
    shouldn't haveã€‚ The problem with ASCII of course is it's the American standard
    codeï¼Œ which is a problemã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­è®¸å¤šç³»ç»Ÿå—åˆ°è¿™äº›ç”µæŠ¥ç¼–ç çš„å½±å“ã€‚å½“ç„¶ï¼Œè¿™å°±æ˜¯æˆ¿é—´é‡Œçš„å¤§è±¡ASCIIï¼Œå®ƒåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¾—ç›ŠäºITA2å’Œæ³¢é“ç”µæŠ¥ç¼–ç ã€‚ä½†ASCIIå®é™…ä¸Šå æ®äº†ä¸–ç•Œï¼Œå°½ç®¡å®ƒä¸è¯¥å¦‚æ­¤ã€‚ASCIIçš„é—®é¢˜åœ¨äºå®ƒæ˜¯ç¾å›½æ ‡å‡†ä»£ç ï¼Œè¿™ç¡®å®æ˜¯ä¸ªé—®é¢˜ã€‚
- en: in a world that contains a lot more countries than America and a lot more languages
    thanï¼Œ Englishã€‚ which meant that of courseï¼Œ even though ASCII was built into a
    lot of systemsã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸€ä¸ªæ‹¥æœ‰æ¯”ç¾å›½æ›´å¤šå›½å®¶å’Œæ›´å¤šè¯­è¨€çš„ä¸–ç•Œä¸­ï¼Œè¿™æ„å‘³ç€å°½ç®¡ASCIIè¢«å†…ç½®åˆ°è®¸å¤šç³»ç»Ÿä¸­ã€‚
- en: '![](img/2a3245dcd9af276985281a539c729f78_9.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_9.png)'
- en: and still is today and a lot of things will assume ASCIIã€‚ Lots of different
    people developed text encodings to represent their languagesï¼Œ their dialectsã€‚
    their regionsï¼Œ their countriesã€‚ There are a huge number of them out thereã€‚ This
    is just a subset that I took from a list that I found onlineã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä»Šä»ç„¶å¦‚æ­¤ï¼Œè®¸å¤šäº‹æƒ…ä¼šå‡è®¾ä½¿ç”¨ASCIIã€‚è®¸å¤šäººå¼€å‘äº†æ–‡æœ¬ç¼–ç æ¥è¡¨ç¤ºä»–ä»¬çš„è¯­è¨€ã€æ–¹è¨€ã€åœ°åŒºå’Œå›½å®¶ã€‚å¤–é¢æœ‰å¤§é‡ä¸åŒçš„ç¼–ç ã€‚è¿™åªæ˜¯æˆ‘ä»ç½‘ä¸Šæ‰¾åˆ°çš„åˆ—è¡¨ä¸­æå–çš„ä¸€ä¸ªå­é›†ã€‚
- en: And of course that brought its own set of problems because how do you work together
    withã€‚ so many different possible encodingsï¼Ÿ How do you avoid the kinds of bugs
    and translation and encoding problems that can come up whenã€‚ you have this many
    different options and you may not even know which of them are beingï¼Œ usedï¼Ÿ
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œè¿™ä¹Ÿå¸¦æ¥äº†è‡ªå·±çš„ä¸€ç³»åˆ—é—®é¢˜ï¼Œå› ä¸ºä½ å¦‚ä½•ä¸å¦‚æ­¤å¤šä¸åŒçš„ç¼–ç æ–¹å¼åˆä½œï¼Ÿå¦‚ä½•é¿å…åœ¨æœ‰è¿™ä¹ˆå¤šä¸åŒé€‰é¡¹æ—¶å‡ºç°çš„é”™è¯¯ã€ç¿»è¯‘å’Œç¼–ç é—®é¢˜ï¼Œä¸”ä½ å¯èƒ½ç”šè‡³ä¸çŸ¥é“ä½¿ç”¨äº†å“ªç§ï¼Ÿ
- en: Wouldn't it be great if we just had one universal agreed-on solutionï¼Ÿ
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬åªæ‹¥æœ‰ä¸€ä¸ªæ™®éè®¤å¯çš„è§£å†³æ–¹æ¡ˆï¼Œé‚£è¯¥å¤šå¥½å•Šï¼Ÿ
- en: '![](img/2a3245dcd9af276985281a539c729f78_11.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_11.png)'
- en: Wellï¼Œ that's what Unicode is supposed to beã€‚ And it's worth pausing for a moment
    to make sure we understand really what Unicode isã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œè¿™å°±æ˜¯Unicodeçš„ç›®çš„ã€‚å€¼å¾—åœä¸‹æ¥æ€è€ƒä¸€ä¸‹ï¼Œç¡®ä¿æˆ‘ä»¬çœŸæ­£ç†è§£Unicodeæ˜¯ä»€ä¹ˆã€‚
- en: '![](img/2a3245dcd9af276985281a539c729f78_13.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_13.png)'
- en: A lot of single page guides will really make a point of saying Unicode is not
    a characterã€‚ set and Unicode is not an encodingã€‚ It's much more productive to
    think of Unicode as a set of databases and specifications andã€‚ rules and properties
    for describing different human writing systems that we know aboutã€‚ And yesã€‚ some
    of those include ways to encode it into binary textã€‚ Yesã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤šå•é¡µæŒ‡å—ä¼šå¼ºè°ƒUnicodeä¸æ˜¯ä¸€ä¸ªå­—ç¬¦é›†ï¼Œä¹Ÿä¸æ˜¯ç¼–ç ã€‚æ›´æœ‰æ•ˆçš„ç†è§£æ–¹å¼æ˜¯å°†Unicodeè§†ä¸ºæè¿°ä¸åŒäººç±»ä¹¦å†™ç³»ç»Ÿçš„æ•°æ®åº“ã€è§„èŒƒã€è§„åˆ™å’Œå±æ€§çš„é›†åˆã€‚æ˜¯çš„ï¼Œå…¶ä¸­ä¸€äº›åŒ…æ‹¬å°†å…¶ç¼–ç ä¸ºäºŒè¿›åˆ¶æ–‡æœ¬çš„æ–¹å¼ã€‚
- en: some of those include sets of charactersï¼Œ but Unicode itself is so much more
    than anyã€‚ of those individual componentsã€‚ And of course that means it's also complexã€‚
    And it really has to beã€‚ If you think about that long list of different encodingsï¼Œ
    Unicode has to try to do the jobã€‚ of all of them and handle all of the things
    that they handledã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ä¸€äº›åŒ…æ‹¬å­—ç¬¦é›†ï¼Œä½† Unicode æœ¬èº«è¿œè¿œè¶…è¿‡ä»»ä½•å•ä¸ªç»„ä»¶ã€‚å½“ç„¶ï¼Œè¿™ä¹Ÿæ„å‘³ç€å®ƒéå¸¸å¤æ‚ã€‚å¦‚æœä½ è€ƒè™‘åˆ°é‚£é•¿é•¿çš„ä¸åŒç¼–ç åˆ—è¡¨ï¼ŒUnicode å¿…é¡»å°½åŠ›å®Œæˆæ‰€æœ‰è¿™äº›ç¼–ç çš„å·¥ä½œï¼Œå¹¶å¤„ç†å®ƒä»¬æ‰€å¤„ç†çš„æ‰€æœ‰å†…å®¹ã€‚
- en: If any given individual encoding only needed to handle perhaps one languages
    or one dialectsã€‚ or one region's particular language and rules for writingï¼Œ but
    Unicode has to be able toã€‚ handle them allã€‚ There's a lot of complexity that's
    just inherent to that taskã€‚ And of course that means it's very different from
    those older single purpose encodingsï¼Œ butã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä»»ä½•ç»™å®šçš„å•ä¸€ç¼–ç åªéœ€è¦å¤„ç†ä¸€ç§è¯­è¨€æˆ–æ–¹è¨€ï¼Œæˆ–ä¸€ä¸ªåœ°åŒºç‰¹å®šè¯­è¨€å’Œä¹¦å†™è§„åˆ™ï¼Œä½† Unicode å¿…é¡»èƒ½å¤Ÿå¤„ç†æ‰€æœ‰ã€‚è¿™é¡¹ä»»åŠ¡æœ¬èº«å°±æœ‰å¾ˆå¤šå¤æ‚æ€§ã€‚å½“ç„¶ï¼Œè¿™æ„å‘³ç€å®ƒä¸é‚£äº›è¾ƒæ—©çš„å•ä¸€ç”¨é€”ç¼–ç æœ‰å¾ˆå¤§ä¸åŒï¼Œä½†ã€‚
- en: different doesn't have to be the same thing as scaryã€‚ And I hope that's something
    you'll take away from this talkã€‚ Now we need to dive a little bit deeper into
    the terminology just to be able to talk usefullyã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸åŒä¸ä¸€å®šè¦ä¸å¯æ€•åˆ’ç­‰å·ã€‚æˆ‘å¸Œæœ›è¿™æ˜¯ä½ ä»è¿™æ¬¡æ¼”è®²ä¸­èƒ½å¸¦èµ°çš„ä¸€ä¸ªè¦ç‚¹ã€‚ç°åœ¨æˆ‘ä»¬éœ€è¦æ›´æ·±å…¥åœ°æ¢è®¨ä¸€ä¸‹æœ¯è¯­ï¼Œä»¥ä¾¿èƒ½å¤Ÿè¿›è¡Œæœ‰ç”¨çš„è®¨è®ºã€‚
- en: '![](img/2a3245dcd9af276985281a539c729f78_15.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_15.png)'
- en: about Unicodeã€‚ So let's stop and do a quick glossary checkã€‚ Because often we
    fall into very informal terminologyã€‚ Like we start talking about charactersã€‚ And
    Unicode does have a concept of characterï¼Œ but it's much more of an abstract entity
    thanã€‚ in those older encodings and character setsã€‚ The basic atoms of Unicodeã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äº Unicodeã€‚è®©æˆ‘ä»¬åœä¸‹æ¥å¿«é€Ÿæ£€æŸ¥ä¸€ä¸‹è¯æ±‡ã€‚å› ä¸ºæˆ‘ä»¬ç»å¸¸é™·å…¥éå¸¸éæ­£å¼çš„æœ¯è¯­ä¸­ã€‚æ¯”å¦‚æˆ‘ä»¬å¼€å§‹è®¨è®ºå­—ç¬¦ã€‚Unicode ç¡®å®æœ‰å­—ç¬¦çš„æ¦‚å¿µï¼Œä½†å®ƒæ¯”æ—§ç¼–ç å’Œå­—ç¬¦é›†ä¸­çš„æ¦‚å¿µæ›´åŠ æŠ½è±¡ã€‚Unicode
    çš„åŸºæœ¬å•å…ƒã€‚
- en: the things that make it up are called code pointsã€‚ And you might try to think
    of a code point as a characterï¼Œ but we're going to see examplesã€‚ of why that's
    riskyã€‚ And Unicode itself is organized into planes of code pointsã€‚ two to the
    16th or 65ï¼Œ536ï¼Œ code points per planeã€‚ Originally there was just one planeã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ç»„æˆå®ƒçš„ä¸œè¥¿ç§°ä¸ºä»£ç ç‚¹ã€‚ä½ å¯ä»¥è¯•ç€å°†ä»£ç ç‚¹è§†ä¸ºå­—ç¬¦ï¼Œä½†æˆ‘ä»¬å°†çœ‹åˆ°ä¸€äº›ä¾‹å­ï¼Œè¯´æ˜è¿™æ ·åšæ˜¯å¤šä¹ˆå±é™©ã€‚Unicode æœ¬èº«è¢«ç»„ç»‡æˆä»£ç ç‚¹å¹³é¢ï¼Œæ¯ä¸ªå¹³é¢æœ‰ 2
    çš„ 16 æ¬¡æ–¹æˆ– 65,536 ä¸ªä»£ç ç‚¹ã€‚æœ€åˆåªæœ‰ä¸€ä¸ªå¹³é¢ã€‚
- en: Now there are 17 of themã€‚ And code points are much like Unicode's concept of
    a characterã€‚ still sort of an abstractï¼Œ entityã€‚ When we start encoding Unicode
    into a binary formatã€‚ we need to translate it into code unitsï¼Œ which are the atoms
    of a binary encodingã€‚ And then if we do want to go up a higher levelï¼Œ if we want
    something that's analogous to whatã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æœ‰ 17 ç§ã€‚ä»£ç ç‚¹ï¼ˆcode pointsï¼‰ä¸ Unicode çš„å­—ç¬¦æ¦‚å¿µéå¸¸ç›¸ä¼¼ï¼Œä»ç„¶æ˜¯æŸç§æŠ½è±¡çš„å®ä½“ã€‚å½“æˆ‘ä»¬å¼€å§‹å°† Unicode ç¼–ç ä¸ºäºŒè¿›åˆ¶æ ¼å¼æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶è½¬æ¢ä¸ºä»£ç å•å…ƒï¼ˆcode
    unitsï¼‰ï¼Œå®ƒä»¬æ˜¯äºŒè¿›åˆ¶ç¼–ç çš„åŸºæœ¬å•å…ƒã€‚å¦‚æœæˆ‘ä»¬æƒ³æå‡åˆ°æ›´é«˜çš„å±‚æ¬¡ï¼Œæƒ³è¦ä¸€äº›ç±»ä¼¼äºä»€ä¹ˆçš„ä¸œè¥¿ã€‚
- en: we would call a characterï¼Œ Unicode has the term "graphymeã€‚"ã€‚ Sometimes you'll
    also see it described as a grapheme clusterã€‚ And there are a couple different
    variationsã€‚ There's legacy grapheme clusters and extended grapheme clustersã€‚ You
    don't really need to know all the differences between those to be able to work
    effectivelyã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç§°ä¹‹ä¸ºå­—ç¬¦ï¼ŒUnicode ä¸­æœ‰ä¸€ä¸ªæœ¯è¯­æ˜¯â€œå›¾å½¢å•å…ƒï¼ˆgraphymeï¼‰â€ã€‚æœ‰æ—¶ä½ è¿˜ä¼šçœ‹åˆ°å®ƒè¢«æè¿°ä¸ºå›¾å½¢å•å…ƒé›†ï¼ˆgrapheme clusterï¼‰ã€‚è€Œä¸”è¿˜æœ‰å‡ ç§ä¸åŒçš„å˜ä½“ï¼ŒåŒ…æ‹¬é—ç•™å›¾å½¢å•å…ƒé›†å’Œæ‰©å±•å›¾å½¢å•å…ƒé›†ã€‚ä½ å¹¶ä¸éœ€è¦äº†è§£å®ƒä»¬ä¹‹é—´çš„æ‰€æœ‰å·®å¼‚å°±èƒ½æœ‰æ•ˆåœ°å·¥ä½œã€‚
- en: with Unicode in Pythonã€‚ But a grapheme isï¼Œ in Unicode's termsã€‚ the smallest
    or the minimally distinctive unit ofï¼Œ writing in a particular systemã€‚ A grapheme
    is the smallest thing such that if you change itï¼Œ you change the meaning ofï¼Œ the
    textã€‚ and there's not a one-to-one correspondence between these and code pointsï¼Œ
    as we're aboutï¼Œ to seeã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Python ä¸­ä½¿ç”¨ Unicodeã€‚ä½†å›¾å½¢å•å…ƒåœ¨ Unicode çš„æœ¯è¯­ä¸­æ˜¯æŒ‡åœ¨ç‰¹å®šç³»ç»Ÿä¸­å†™ä½œçš„æœ€å°æˆ–æœ€å°å¯åŒºåˆ†å•å…ƒã€‚å›¾å½¢å•å…ƒæ˜¯è¿™æ ·çš„æœ€å°å•ä½ï¼Œå¦‚æœä½ æ”¹å˜å®ƒï¼Œå°±ä¼šæ”¹å˜æ–‡æœ¬çš„å«ä¹‰ã€‚è€Œä¸”è¿™ä¸ä»£ç ç‚¹ä¹‹é—´å¹¶æ²¡æœ‰ä¸€ä¸€å¯¹åº”å…³ç³»ï¼Œæ­£å¦‚æˆ‘ä»¬å³å°†çœ‹åˆ°çš„ã€‚
- en: So let's look at some examples of code pointsã€‚ Here's one that's probably familiar
    to a lot of peopleã€‚ It's just a Latin capital letter Aï¼Œ as you can see from the
    nameã€‚ Its code point is 0041ã€‚ Code points are always a numberã€‚ By traditionï¼Œ they're
    expressed in hexadecimalã€‚ And we can see that it has a block and a category and
    some other informationã€‚ And in factã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆè®©æˆ‘ä»¬çœ‹çœ‹ä¸€äº›ä»£ç ç‚¹çš„ä¾‹å­ã€‚è¿™æ˜¯ä¸€ä¸ªè®¸å¤šäººå¯èƒ½ç†Ÿæ‚‰çš„ä¾‹å­ã€‚å®ƒå°±æ˜¯ä¸€ä¸ªæ‹‰ä¸å¤§å†™å­—æ¯ Aï¼Œä»åç§°å¯ä»¥çœ‹å‡ºã€‚å®ƒçš„ä»£ç ç‚¹æ˜¯ 0041ã€‚ä»£ç ç‚¹æ€»æ˜¯ä¸€ä¸ªæ•°å­—ã€‚æ ¹æ®ä¼ ç»Ÿï¼Œå®ƒä»¬ä»¥åå…­è¿›åˆ¶è¡¨ç¤ºã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒæœ‰ä¸€ä¸ªå—ã€ä¸€ä¸ªç±»åˆ«å’Œä¸€äº›å…¶ä»–ä¿¡æ¯ã€‚äº‹å®ä¸Šã€‚
- en: this is just a subset of the information Unicode has on this code pointã€‚ Blocks
    are a way of organizing code points below the level of a planeã€‚ Blocks are contiguous
    sets of code points that are all relatedã€‚ So for exampleã€‚ the basic Latin block
    contains the code points for the Latin alphabetï¼Œ orã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªæ˜¯Unicodeåœ¨è¿™ä¸ªä»£ç ç‚¹ä¸Šä¿¡æ¯çš„ä¸€ä¸ªå­é›†ã€‚åŒºå—æ˜¯ä¸€ç§ç»„ç»‡ä»£ç ç‚¹çš„æ–¹å¼ï¼Œä½äºå¹³é¢çº§åˆ«ã€‚åŒºå—æ˜¯æ‰€æœ‰ç›¸å…³çš„ä»£ç ç‚¹çš„è¿ç»­é›†åˆã€‚ä¾‹å¦‚ï¼ŒåŸºæœ¬æ‹‰ä¸åŒºå—åŒ…å«æ‹‰ä¸å­—æ¯çš„ä»£ç ç‚¹ã€‚
- en: at least the most common parts of itã€‚ It has a lot of overlap with ASCIIã€‚ In
    factã€‚ the first 128 code points in Unicode match the 128 values in ASCIIã€‚ We can
    see its categoryã€‚ It's an uppercase letterã€‚ We can see it has information about
    bi-directionalityã€‚ English and most other Western European languagesï¼Œ are written
    left to rightã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è‡³å°‘æ˜¯å®ƒæœ€å¸¸è§çš„éƒ¨åˆ†ã€‚å®ƒä¸ASCIIæœ‰å¾ˆå¤§çš„é‡å ã€‚äº‹å®ä¸Šï¼ŒUnicodeä¸­çš„å‰128ä¸ªä»£ç ç‚¹ä¸ASCIIä¸­çš„128ä¸ªå€¼ç›¸åŒ¹é…ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒçš„ç±»åˆ«ï¼Œå®ƒæ˜¯ä¸€ä¸ªå¤§å†™å­—æ¯ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒæœ‰å…³äºåŒå‘æ€§çš„ç›¸å…³ä¿¡æ¯ã€‚è‹±è¯­å’Œå¤§å¤šæ•°å…¶ä»–è¥¿æ¬§è¯­è¨€æ˜¯ä»å·¦åˆ°å³ä¹¦å†™çš„ã€‚
- en: There's also this combining class propertyï¼Œ which we'll get to in just a secondã€‚
    Of courseã€‚ there's a lot more that you could look up if you went trolling through
    all ofã€‚ the information in the Unicode databaseã€‚ So let's look at something a
    little bit more complicatedã€‚ This is code ã€‚0308ï¼Œ which by itself doesn't really
    do anythingã€‚ It wants to go with something elseã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰è¿™ä¸ªç»„åˆç±»å±æ€§ï¼Œæˆ‘ä»¬ç¨åä¼šè®¨è®ºã€‚å½“ç„¶ï¼Œå¦‚æœä½ å»ç¿»é˜…Unicodeæ•°æ®åº“ä¸­çš„æ‰€æœ‰ä¿¡æ¯ï¼Œè¿˜æœ‰å¾ˆå¤šå†…å®¹å¯ä»¥æŸ¥é˜…ã€‚é‚£ä¹ˆè®©æˆ‘ä»¬çœ‹çœ‹ä¸€äº›ç¨å¾®å¤æ‚çš„å†…å®¹ã€‚è¿™æ˜¯ä»£ç 0308ï¼Œå•ç‹¬æ¥çœ‹å¹¶æ²¡æœ‰ä»€ä¹ˆä½œç”¨ã€‚å®ƒæƒ³ä¸å…¶ä»–ä¸œè¥¿ä¸€èµ·ä½¿ç”¨ã€‚
- en: And when it doesï¼Œ it shows up as an accent markï¼Œ diuresisï¼Œ or sometimes you
    might callã€‚ it an umlaut or just dotã€‚ But here we can seeï¼Œ for exampleã€‚ that combining
    class value suddenly shows up has a value ofï¼Œ 230ã€‚ which says when we're rendering
    this and we see this in a sequence of code pointsã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å®ƒå‡ºç°æ—¶ï¼Œå®ƒæ˜¾ç¤ºä¸ºé‡éŸ³ç¬¦å·ã€äºŒé‡éŸ³ç¬¦ï¼Œæˆ–è€…æœ‰æ—¶ä½ å¯èƒ½ç§°ä¹‹ä¸ºå˜éŸ³ç¬¦æˆ–åªæ˜¯ç‚¹ã€‚ä½†åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä¾‹å¦‚ï¼Œç»„åˆç±»å€¼çªç„¶æ˜¾ç¤ºå‡º230çš„å€¼ï¼Œè¿™è¡¨ç¤ºå½“æˆ‘ä»¬æ¸²æŸ“è¿™ä¸ªå¹¶åœ¨ä¸€ç³»åˆ—ä»£ç ç‚¹ä¸­çœ‹åˆ°å®ƒæ—¶ã€‚
- en: it shows up above whatever came before itã€‚ And there are different values for
    combining class to show positioning and how differentã€‚ things combine together
    to form a single visible glyph on your screen or when printedã€‚ But notice that
    this means if we want that u with an umlaut above itï¼Œ we're using multipleã€‚ code
    points to produce what is one character from the human reader's perspectiveã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæ˜¾ç¤ºåœ¨ä¹‹å‰çš„å†…å®¹ä¹‹ä¸Šã€‚ç»„åˆç±»æœ‰ä¸åŒçš„å€¼ï¼Œç”¨äºæ˜¾ç¤ºå®šä½ä»¥åŠä¸åŒäº‹ç‰©æ˜¯å¦‚ä½•ç»„åˆåœ¨ä¸€èµ·å½¢æˆå•ä¸ªå¯è§çš„å­—å½¢ï¼Œæ— è®ºæ˜¯åœ¨å±å¹•ä¸Šè¿˜æ˜¯æ‰“å°æ—¶ã€‚ä½†è¯·æ³¨æ„ï¼Œè¿™æ„å‘³ç€å¦‚æœæˆ‘ä»¬æƒ³è¦å¸¦æœ‰å˜éŸ³ç¬¦å·çš„uï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨å¤šä¸ªä»£ç ç‚¹æ¥ç”Ÿæˆä»äººç±»è¯»è€…çš„è§’åº¦æ¥çœ‹æ˜¯ä¸€ä¸ªå­—ç¬¦çš„å†…å®¹ã€‚
- en: So we've already broken that concept of one code point is one character because
    here weã€‚ have a character that uses two code pointsã€‚ And it actually goes the
    actual complexity shows up in both directionsã€‚ For exampleï¼Œ here this character
    from the Arabic sections of Unicode is one code pointã€‚ but 18 charactersã€‚ And
    there are actually several of these in Unicodeã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å·²ç»æ‰“ç ´äº†ä¸€ä¸ªä»£ç ç‚¹å°±æ˜¯ä¸€ä¸ªå­—ç¬¦çš„æ¦‚å¿µï¼Œå› ä¸ºè¿™é‡Œæˆ‘ä»¬æœ‰ä¸€ä¸ªä½¿ç”¨ä¸¤ä¸ªä»£ç ç‚¹çš„å­—ç¬¦ã€‚å®é™…ä¸Šï¼Œå¤æ‚æ€§åœ¨ä¸¤ä¸ªæ–¹å‘ä¸Šéƒ½æ˜¾ç°å‡ºæ¥ã€‚ä¾‹å¦‚ï¼Œè¿™ä¸ªæ¥è‡ªUnicodeé˜¿æ‹‰ä¼¯è¯­éƒ¨åˆ†çš„å­—ç¬¦æ˜¯ä¸€ä¸ªä»£ç ç‚¹ï¼Œä½†æœ‰18ä¸ªå­—ç¬¦ã€‚å®é™…ä¸Šï¼ŒUnicodeä¸­æœ‰å‡ ä¸ªè¿™æ ·çš„ä¾‹å­ã€‚
- en: These are used in Arabic religious type setting where there are certain phrases
    that tendã€‚ to occur quite often and there are ligatures for representing them
    just as a single unitã€‚ when type setting and when printing and displayingã€‚ But
    againã€‚ we see you can't assume one code point is one character and in fact this
    isã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ç”¨äºé˜¿æ‹‰ä¼¯å®—æ•™æ’ç‰ˆï¼Œå…¶ä¸­æœ‰äº›çŸ­è¯­ç›¸å½“å¸¸è§ï¼Œå¹¶ä¸”æœ‰è¿å­—å°†å®ƒä»¬è¡¨ç¤ºä¸ºä¸€ä¸ªå•å…ƒã€‚åœ¨æ’ç‰ˆã€æ‰“å°å’Œæ˜¾ç¤ºæ—¶ã€‚ä½†å†æ¬¡å¼ºè°ƒï¼Œæˆ‘ä»¬çœ‹åˆ°ä½ ä¸èƒ½å‡è®¾ä¸€ä¸ªä»£ç ç‚¹å°±æ˜¯ä¸€ä¸ªå­—ç¬¦ï¼Œå®é™…ä¸Šè¿™æ˜¯ã€‚
- en: one code point that isn't necessarily even one wordã€‚ So Unicode yes can be complex
    and yes you need to know that there's a difference betweenã€‚ code points and characters
    and graphimsã€‚ But when you sit down and think about itã€‚ any system that tries
    to handle all of the complexityã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªä»£ç ç‚¹å¹¶ä¸ä¸€å®šæ˜¯ä¸€ä¸ªå•è¯ã€‚å› æ­¤ï¼ŒUnicodeç¡®å®å¯ä»¥å¾ˆå¤æ‚ï¼Œè€Œä¸”ä½ éœ€è¦çŸ¥é“ä»£ç ç‚¹ã€å­—ç¬¦å’Œå›¾å½¢ä¹‹é—´çš„åŒºåˆ«ã€‚ä½†æ˜¯ï¼Œå½“ä½ åä¸‹æ¥æ€è€ƒè¿™ä¸ªé—®é¢˜æ—¶ï¼Œä»»ä½•è¯•å›¾å¤„ç†æ‰€æœ‰å¤æ‚æ€§çš„ç³»ç»Ÿéƒ½ä¼šé¢ä¸´æŒ‘æˆ˜ã€‚
- en: of human writing sooner or later is going to run into something like this and
    is goingã€‚ to present this level of complexity to you in some wayã€‚ And of course
    it keeps going because this means that often in Unicode there are multipleã€‚ ways
    to write the same thingã€‚ Going back to that you with the umlop above itã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: äººç±»ä¹¦å†™æœ€ç»ˆè¿Ÿæ—©ä¼šé‡åˆ°è¿™æ ·çš„å¤æ‚æ€§ï¼Œå¹¶ä»¥æŸç§æ–¹å¼å‘ä½ å±•ç¤ºè¿™ç§å¤æ‚æ€§ã€‚å½“ç„¶ï¼Œè¿™ç§æƒ…å†µè¿˜åœ¨ç»§ç»­ï¼Œå› ä¸ºè¿™æ„å‘³ç€åœ¨Unicodeä¸­ï¼Œé€šå¸¸æœ‰å¤šç§æ–¹å¼æ¥å†™åŒæ ·çš„ä¸œè¥¿ã€‚å›åˆ°é‚£ä¸ªå¸¦æœ‰å˜éŸ³ç¬¦å·çš„uã€‚
- en: there are at least two ways you can writeï¼Œ this in Unicodeã€‚ Here's the one we
    saw earlier that uses the combining accent characterã€‚ There's also a pre composed
    form that does it in one code pointã€‚ And this is there for historical reasonsã€‚
    A lot of earlier encodings that were single purpose had pre composed characters
    for differentã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: combinations of letters and accent marksã€‚ And so for compatibility Unicode has
    to have them as well so that you can do a lossless conversionã€‚ to and from Unicode
    back to your original encodingã€‚ If you ever want toã€‚ But this means that in Unicode
    we can end up with multiple ways to write the same thingã€‚ And these two sequences
    of code points where the one pre composed point and the decomposedã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: sequence of two code points are considered equivalentã€‚ And in fact Unicode calls
    them canonically equivalent because it should always be safeã€‚ to swap one of these
    for the otherã€‚ You won't change the meaning of your text by doing soã€‚ But it also
    has a concept of compatibility equivalence which is where it may not alwaysã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: be safe to swap between two different ways of writing the same thingã€‚ So here
    for example we have a code point that represents a composed fraction one half
    andã€‚ a decomposed sequence that writes it out as a one and a two with a splash
    between themã€‚ There are times when it's correct to swap between these there are
    also times when it'sï¼Œ notã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: And this gives rise to the concept of normalizationã€‚ Which is a way that we
    can take different sequences that may represent the same thingã€‚ and find out if
    they do by making them equal after the normalizationã€‚ And because Unicode has
    both composed and decomposed forms and has two different typesã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: of equivalentsã€‚ There are four different ways to normalize Unicode depending
    on what the result shouldã€‚ look like and what rules you want to applyã€‚ So you
    can either get a composed or a decomposed form after the normalizationã€‚ You can
    use either canonical or compatibility equivalence rules as you're doing thisã€‚
    Now we'll get to this a little bit later on but if you're just feeling overwhelmed
    andã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: want a general recommendation if you ever need to do Unicode normalization yourselfã€‚
    it's probably best to pick form NFKCã€‚ That's the one that will make the most trade-offs
    in favor of what you probably want but we'llã€‚ see examples of how different normalization
    forms can be good or bad a little bit laterï¼Œ onã€‚ Speaking of multiple ways of
    writing the same thing though a lot of languages have multipleã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: different forms for different charactersï¼Œ uppercase and lowercase and in fact
    Unicode has threeã€‚ different cases lowercaseï¼Œ uppercase and title case and multiple
    different case mappingsã€‚ and ways of transforming characters according to case
    as well as the concept of completelyã€‚ uncased charactersã€‚ And in fact most code
    points in Unicode were most characters abstract entities that Unicodeã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: handles are uncased because the case mappings won't change them because they're
    coming fromã€‚ languages or systems of symbols that just don't have a concept of
    caseã€‚ Now you might be wondering well how then do I do things like case insensitive
    comparisonsã€‚ especially because Unicode if you dig into it has at least three
    different concepts ofã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: case and ways to find out what case a character is or whether it even is case
    and the answerã€‚ is case folding which Python supports and we'll see examples of
    it in a little bit but I doã€‚ want to call out that Python's documentation says
    something not greatã€‚ Python says case folding is like a more aggressive form of
    lowercase and while it's true thatã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: for a lot of Western European languages the result of case folding will look
    lowercase thisã€‚ is not a guarantee there are languages where the result of case
    folding will look uppercaseã€‚ So don't think of case folding as being uppercasing
    or lower casing it is its own thing but theã€‚ important thing to know about case
    folding is that after you've case folded two stringsã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: if they differed only in case they will be the same after the foldã€‚ And of course
    case can also extend beyond what Unicode really handlesã€‚ Unicode handles most
    of these cases for example the Greek Sigma which takes different formsã€‚ depending
    on where it occurs in a word the Turkic languages have both dotted and dotlessã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: forms of the letter I and it's incredibly important to preserve the dot or absence
    ofã€‚ the dot when you're doing a case transformation because those effect meaning
    German has thisã€‚ character officially it's called the sharp s historically it
    didn't have an uppercase formã€‚ and so it uppercases to SS but this also means
    that case mappings in Unicode aren't transitiveã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: because uppercasing this and then lower casing again won't get you back what
    you startedã€‚ with and there's far more complexity in the language of that have
    case that Unicode justã€‚ doesn't handle and tells you you may need to have low-calaware
    rules there are situationsã€‚ like for example Dutch where words that begin with
    ij have to title case that as a singleã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: unit rather than as two characters and Unicode simply tells you you need to
    get low-calawareã€‚ rules for the specific language you're going to work with it
    handles some of these butã€‚ nowhere near all the complexity that exists in all
    the languages now finally we need toã€‚ understand since we're going to work with
    computers how we actually get this into aã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: computer which means how do we get it into a binary form how do we encode it
    and decodeã€‚ it going between code points which are numeric values but kind of
    abstract to actual bitsã€‚ and bytes and to do that we need a Unicode transformation
    format and there are a lot ofã€‚ those I've listed some here the two you'll see
    most often are probably UTF-8 and UTF-16ã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: but it's worth being aware that most of these are variable width they use different
    numbersã€‚ of bytes to encode different code points UTF-8 for example for a code
    point from theã€‚ ASCII range only needs one byte but for other code points may
    need up to four UTF-16 forã€‚ anything in the lowest numbered plane plane zero or
    the basic multilingual plane BMP asã€‚
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: you'll sometimes see it written uses two bytes for anything from higher numbered
    planes usesã€‚ four bytes because originally Unicode had just the one plane and
    it had two to the sixteenthã€‚ code points in it so there was an assumption that
    16 bits ought to be enough for anybodyã€‚ right well eventually Unicode added more
    planes and UTF-16 was developed with a scheme thatã€‚
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: lets it still handle 16 bit units but sometimes use two of them per code point
    the exact mechanicsã€‚ if you want to go look it up are called surrogate pairs and
    basically there is a segment ofã€‚ plane zero of Unicode that set aside that will
    never be assigned and UTF-16 transformsã€‚ a code point bigger than 16 bits into
    two code points from that range and then you canã€‚
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: transform them back again to get back the original value and this is how UTF-16
    handles thoseã€‚ code points that are larger than 16 bits but that also means that
    it too now is a variableã€‚ with encoding and of course we need to consider what
    kind of abstractions we're going to exposeã€‚ to a programmer because there are
    different ways we can handle strings in programming languagesã€‚
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: they might be sequences of bytes they might be sequences of the encodings code
    units orã€‚ they might be sequences of code points or sequences of graph themes
    and their trade-offsã€‚ involved in all of these one of the important things to
    be aware of though is dependingã€‚ on the abstraction your language chose you may
    or may not be able to cause changes inã€‚
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: meaning or even completely invalidate a sequence of code points by cutting into
    it so for exampleã€‚ in a language like see where typically strings are exposed
    as a sequence of bytes if youã€‚ arbitrarily cut in the middle of that you might
    cut in the middle of a multi byte code unitã€‚ or you might cut in the middle of
    a code point that requires multiple bytes or you mightã€‚
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: be cutting at a code point boundary but cutting in the middle of a graph theme
    that's madeã€‚ up of multiple code points all of these operations can be unsafe
    and depending on which abstractionã€‚ your language exposes to you you may be at
    risk of different versions of these problemsã€‚
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a3245dcd9af276985281a539c729f78_17.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
- en: now you might be wondering well what does Python do and you might also be wonderingã€‚
    well we're twenty minutes into this and you haven't really talked about Python
    I thoughtã€‚ this was a Python talk well okay let's talk about Python originally
    there was Python 2ã€‚
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a3245dcd9af276985281a539c729f78_19.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
- en: and Python 2's story for Unicode was not that great in Python 2 the string type
    was a sequenceã€‚ of bytes there was a separate type called the Unicode that was
    a Unicode string it offeredã€‚ access to lots of features of Unicode it could represent
    any code point in Unicode or at leastã€‚ sometimes could we'll get to that in a
    minute and you had to know to convert back and forthã€‚
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œ Python 2 çš„ Unicode æ•…äº‹å¹¶ä¸å¥½ã€‚åœ¨ Python 2 ä¸­ï¼Œå­—ç¬¦ä¸²ç±»å‹æ˜¯å­—èŠ‚çš„åºåˆ—ï¼Œè¿˜æœ‰ä¸€ç§ç§°ä¸º Unicode çš„å•ç‹¬ç±»å‹ï¼Œå®ƒæ˜¯
    Unicode å­—ç¬¦ä¸²ï¼Œæä¾›äº†å¯¹è®¸å¤š Unicode ç‰¹æ€§çš„è®¿é—®ã€‚å®ƒå¯ä»¥è¡¨ç¤º Unicode ä¸­çš„ä»»ä½•ä»£ç ç‚¹ï¼Œæˆ–è€…è‡³å°‘æœ‰æ—¶å¯ä»¥ï¼Œç¨åæˆ‘ä»¬ä¼šè®¨è®ºè¿™ä¸€ç‚¹ï¼Œè€Œä½ å¿…é¡»çŸ¥é“å¦‚ä½•è¿›è¡Œç›¸äº’è½¬æ¢ã€‚
- en: between them and you had to know what encodings things came from and we're going
    to and Pythonã€‚ assumed ASCII by default for its byte strings and even if you told
    it otherwise still aã€‚ lot of third-party modules and other code didn't behave
    all that well when you presentedã€‚ them with non-asky byte sequences or even sometimes
    with just Unicode instances and thisã€‚
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¿…é¡»çŸ¥é“ä¸œè¥¿æ¥è‡ªä»€ä¹ˆç¼–ç ï¼Œä»¥åŠè¦è½¬åˆ°ä»€ä¹ˆåœ°æ–¹ã€‚Python é»˜è®¤å‡è®¾å­—èŠ‚å­—ç¬¦ä¸²ä¸º ASCIIï¼Œå³ä½¿ä½ å‘Šè¯‰å®ƒå…¶ä»–ä¿¡æ¯ï¼Œè®¸å¤šç¬¬ä¸‰æ–¹æ¨¡å—å’Œå…¶ä»–ä»£ç åœ¨ä½ æä¾›é
    ASCII å­—èŠ‚åºåˆ—æˆ–æœ‰æ—¶åªæ˜¯ Unicode å®ä¾‹æ—¶ï¼Œä¹Ÿå¹¶ä¸é‚£ä¹ˆå¥½ç”¨ã€‚
- en: was generally a mess so now we have Python 3 and there was much rejoicing because
    in Pythonã€‚ 3 there's only one string type and it is a Unicode string type there
    is still a separateã€‚ type for sequences of bytes and you can go back and forth
    between them you can take aã€‚ byte sequence and if you know the encoding you can
    decode it into a string or you canã€‚
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é€šå¸¸æ˜¯ä¸ªéº»çƒ¦ï¼Œæ‰€ä»¥ç°åœ¨æˆ‘ä»¬æœ‰äº† Python 3ï¼Œå¤§å®¶éƒ½å¾ˆé«˜å…´ï¼Œå› ä¸ºåœ¨ Python 3 ä¸­åªæœ‰ä¸€ç§å­—ç¬¦ä¸²ç±»å‹ï¼Œé‚£å°±æ˜¯ Unicode å­—ç¬¦ä¸²ç±»å‹ã€‚ä»ç„¶æœ‰ä¸€ä¸ªå•ç‹¬çš„å­—èŠ‚åºåˆ—ç±»å‹ï¼Œä½ å¯ä»¥åœ¨å®ƒä»¬ä¹‹é—´æ¥å›è½¬æ¢ã€‚å¦‚æœä½ çŸ¥é“ç¼–ç ï¼Œå¯ä»¥å°†å­—èŠ‚åºåˆ—è§£ç ä¸ºå­—ç¬¦ä¸²ï¼Œæˆ–è€…ä½ å¯ä»¥ã€‚
- en: take a string and encode it into bytes in a particular encoding but a lot of
    the issuesã€‚ that used to exist in Python 2 especially with the sort of interchangeability
    that it hadã€‚ for both Unicode and byte strings have been cleaned up except for
    one thing that persistedã€‚ for a few releases into the Python 3 series and it's
    this this is everybody's favoriteã€‚
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å–ä¸€ä¸ªå­—ç¬¦ä¸²å¹¶å°†å…¶ç¼–ç ä¸ºç‰¹å®šç¼–ç çš„å­—èŠ‚ï¼Œä½†åœ¨ Python 2 ä¸­å­˜åœ¨çš„è®¸å¤šé—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ Unicode å’Œå­—èŠ‚å­—ç¬¦ä¸²ä¹‹é—´çš„å¯äº’æ¢æ€§é—®é¢˜ï¼Œå·²ç»å¾—åˆ°æ¸…ç†ï¼Œé™¤äº†ä¸€ä¸ªåœ¨
    Python 3 ç³»åˆ—ä¸­æŒç»­äº†å‡ ä¸ªç‰ˆæœ¬çš„é—®é¢˜ï¼Œè¿™å°±æ˜¯æ¯ä¸ªäººçš„æœ€çˆ±ã€‚
- en: emoji the pile of poo and if you fire up a Python interpreter from Python 3ã€‚0ã€‚1ã€‚2
    there'sã€‚ a good chance you will see this result and you might be wondering what's
    going on hereã€‚ well earlier versions of Python when you compiled the interpreter
    you made a choice as to howã€‚ it would store Unicode internally and effectively
    the choice was between UTF-16 and UTF-32 soã€‚
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨æƒ…ç¬¦å·â€œä¾¿ä¾¿â€ï¼Œå¦‚æœä½ ä» Python 3.0.1.2 å¯åŠ¨ä¸€ä¸ª Python è§£é‡Šå™¨ï¼Œçœ‹åˆ°è¿™ä¸ªç»“æœçš„æœºä¼šå¾ˆå¤§ï¼Œä½ å¯èƒ½ä¼šæƒ³ï¼Œå‘ç”Ÿäº†ä»€ä¹ˆäº‹ã€‚æ—©æœŸç‰ˆæœ¬çš„
    Python ç¼–è¯‘è§£é‡Šå™¨æ—¶ï¼Œä½ éœ€è¦é€‰æ‹©å¦‚ä½•åœ¨å†…éƒ¨å­˜å‚¨ Unicodeï¼Œå®é™…ä¸Šé€‰æ‹©æ˜¯ UTF-16 å’Œ UTF-32 ä¹‹é—´çš„é€‰æ‹©ï¼Œå› æ­¤ã€‚
- en: either 16-bit or 32-bit storage for Unicode these were called narrow and wide
    builds ofã€‚ Python most people used a narrow build and that's where you would see
    this result becauseã€‚ that code point is too large to fit in a single 16-bit unit
    so an encoding like UTF-16 needsã€‚ to use a surrogate pair for it and split it
    across two replacement code points and Pythonã€‚
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ 16 ä½æˆ– 32 ä½å­˜å‚¨ Unicodeï¼Œè¿™è¢«ç§°ä¸º Python çš„çª„å’Œå®½æ„å»ºã€‚å¤§å¤šæ•°äººä½¿ç”¨çª„æ„å»ºï¼Œè¿™å°±æ˜¯ä½ ä¼šçœ‹åˆ°è¿™ä¸ªç»“æœçš„åœ°æ–¹ï¼Œå› ä¸ºè¿™ä¸ªä»£ç ç‚¹å¤ªå¤§ï¼Œæ— æ³•å®¹çº³åœ¨ä¸€ä¸ª
    16 ä½å•å…ƒä¸­ï¼Œå› æ­¤åƒ UTF-16 è¿™æ ·çš„ç¼–ç éœ€è¦ä½¿ç”¨ä»£ç†å¯¹æ¥å¤„ç†ï¼Œå¹¶å°†å…¶åˆ†æˆä¸¤ä¸ªæ›¿ä»£ä»£ç ç‚¹ï¼Œè€Œ Pythonã€‚
- en: would expose this to you directly if you iterated over this you would see two
    code points fromã€‚ the surrogate range in the basic multilingual plane instead
    of the original code point youã€‚ put in now fortunately that's been fixed Python
    3ã€‚3 changed this implemented a spec from pepã€‚ 393 which did away with the narrow
    and wide builds of Python if you want to know the detailsã€‚
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ é€æ­¥æŸ¥çœ‹è¿™ä¸ªï¼Œä½ å°†ç›´æ¥æš´éœ²ç»™ä½ ä¸¤ä¸ªæ¥è‡ªåŸºæœ¬å¤šè¯­è¨€å¹³é¢çš„ä»£ç†èŒƒå›´çš„ä»£ç ç‚¹ï¼Œè€Œä¸æ˜¯ä½ ç°åœ¨è¾“å…¥çš„åŸå§‹ä»£ç ç‚¹ã€‚å¹¸è¿çš„æ˜¯ï¼ŒPython 3.3 ä¿®å¤äº†è¿™ä¸ªé—®é¢˜ï¼Œå®æ–½äº†
    PEP 393 çš„è§„èŒƒï¼Œæ¶ˆé™¤äº† Python çš„çª„å’Œå®½æ„å»ºã€‚å¦‚æœä½ æƒ³çŸ¥é“æ›´å¤šç»†èŠ‚ã€‚
- en: and how that affected in memory storage and how it affects the capi of Python
    you can goã€‚ look up the pep one other nice takeaway is that it means Python strings
    use a lot lessã€‚ memory now on average than they used to but the big thing for
    our purposes is it meansã€‚ that a Python string now really is a sequence of code
    points where previously it was a sequenceã€‚
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠå®ƒå¦‚ä½•å½±å“å†…å­˜å­˜å‚¨å’Œ Python çš„ C APIï¼Œä½ å¯ä»¥å»æŸ¥é˜… PEPã€‚å¦ä¸€ä¸ªä¸é”™çš„æ”¶è·æ˜¯ï¼Œè¿™æ„å‘³ç€ Python å­—ç¬¦ä¸²ç°åœ¨å¹³å‡ä½¿ç”¨çš„å†…å­˜è¦æ¯”ä»¥å‰å°‘å¾—å¤šï¼Œä½†å¯¹æˆ‘ä»¬æ¥è¯´ï¼Œæœ€é‡è¦çš„æ˜¯ï¼Œè¿™æ„å‘³ç€
    Python å­—ç¬¦ä¸²ç°åœ¨ç¡®å®æ˜¯ä¸€ç³»åˆ—ä»£ç ç‚¹ï¼Œè€Œä¹‹å‰æ˜¯ä¸€ä¸ªåºåˆ—ã€‚
- en: of code units and this is actually a test I like to use with different languages
    whenã€‚ I try them out is take a string like the pile of poo and ask the language
    how long is thisã€‚ if you get an answer of one that means the language is probably
    working with either codeã€‚ points or graph themes as its string abstraction if
    you get an answer of more than one then maybeã€‚
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: it's working with code units like Python used to with its 2-byte 16-bit encoding
    on narrowã€‚ builds or maybe even at something more complex like just exposing sequences
    of UTF-8 bytesã€‚ which will give you an even larger answer on some of the emoji
    but it's a good way toã€‚ quickly find out what is a language doing and what abstraction
    is it exposing when itã€‚
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: says it has Unicode support because that's an important thing to know now as
    far as Pythonã€‚ we now have strings which are sequences of code points which means
    that we can find outã€‚ information about them if we grab something out of a string
    so a string of length one it'sã€‚ a single code point if we iterate a string we're
    iterating over code points if we if weã€‚
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: take a slice of a string or index into a string we're getting code points and
    we can actuallyã€‚ find out what's the numeric value of a code point and we can
    transform it into hexadecimalã€‚ as a tradition for representing Unicode code points
    there's also a module in the standardã€‚ library that's really useful called Unicode
    data and this gives us a lot of access to theã€‚
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Unicode databases and the information that Unicode provides about its code points
    andã€‚ characters so we can ask questions like what's the name of this code point
    or what categoryã€‚ is it assigned to what's its bidirectional or combining rendering
    behavior all of whichã€‚ can be useful information to find out we also have access
    from that module to Unicode normalizationã€‚
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: and we can use any Unicode normalization form we want and so here for example
    we can takeã€‚ that pre-composed u with umlaut character and decompose it into the
    two code points sequenceã€‚ or we can take that pre-composed one half fraction and
    decompose it using compatibilityã€‚ equivalence into that sequence of one slash
    two we also have access in Python to case foldingã€‚
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: which is useful gives us access to case insensitive comparison and anytime you
    need to do a caseã€‚ insensitive string comparison in Python this is what you should
    be reaching for a lot ofã€‚ us probably developed habits from earlier days when
    we weren't working with Unicode ofã€‚ upper casing or lower casing and a lot of
    us probably still do that when working with databasesã€‚
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: because we may not have a case fold abstraction in our sequel libraries or in
    our databaseã€‚ but in Python we have that available and that's how we should be
    doing case insensitive comparisonsã€‚
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a3245dcd9af276985281a539c729f78_21.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
- en: of strings so everything is wonderful right obviously well yes in a way Python
    three andã€‚ especially since three point three does a good job of implementing
    Unicode and exposingã€‚ it in a useful way and making it relatively easy for us
    to work with but there are stillã€‚ traps and problems that we can fall into one
    of which I'm not normally a fan of absoluteã€‚
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a3245dcd9af276985281a539c729f78_23.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
- en: statements but this is one that I will get pretty absolute on I will call this
    the goldenã€‚ rule of working with text in any sort of programming language not
    just Python is to be aware ofã€‚ your programs boundaries and do encoding and decoding
    there and only there and when I sayã€‚ boundaries I mean things like if your program
    reads and writes files then that's a boundaryã€‚
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: when it opens up and reads the contents of a file or writes the contents back
    onto theã€‚ file system if your program talks over a network that's a boundary when
    it sends informationã€‚ out over that connection or receives information coming
    in those are the points where you shouldã€‚ do your encoding and decoding those
    are the points where you should be working with bytesã€‚
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: objects but once you have them encoded or decoded you should be working entirely
    withã€‚ strings internally you should not be passing around bytes objects or dealing
    with encodedã€‚ sequences of bytes at almost any cost because most older approaches
    and most older Pythonã€‚ code that had trouble making the jump two to three had
    trouble because of this becauseã€‚
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: of mixing of byte strings and Unicode strings or even just not using Unicode
    strings at allã€‚ in some cases and not thinking about encoding and decoding and
    where they needed to happenã€‚ so this is your golden rule if you take nothing else
    away look for the boundaries of yourã€‚ program identify what they are do your encoding
    and decoding there and only there everywhereã€‚
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: else be working with strings be working with real Unicode now there is still
    some difficultyã€‚ every once in a while especially when it comes to working with
    files and especially on certainã€‚ types of Unix operating systems and these problems
    fall into a few different categories thereã€‚ are some systems where there is no
    reliable way to ask the system what encoding it usesã€‚
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: for its file system so you know that something like a file name is a sequence
    of bytes butã€‚ you might not have any way of figuring out how to decode that into
    a sequence of Unicodeã€‚ code points there are also file systems where technically
    there is not a requirement thatã€‚ they be able to decode where a path can simply
    be any arbitrary sequence of bytes you wantã€‚
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: and never validly decode in any known encoding and Python has made progress
    over the courseã€‚ of the Python 3 release series with getting better at this there
    are some tips and tricksã€‚ and tools and now Python mostly does its best to let
    you treat the file system as UTF-8ã€‚ with some tricks to handle potentially invalid
    or just completely undecodable paths actuallyã€‚
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: what Python does now is similar to what UTF-16 does where when it encounters
    a byte thatã€‚ can't possibly decode as a sequence of code points it preserves it
    as is by transformingã€‚ it into a code point from the surrogate pair range and
    that lets it transform back intoã€‚ the original byte again when it's time to write
    things on the file system or do otherã€‚
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Pythonç°åœ¨æ‰€åšçš„ç±»ä¼¼äºUTF-16çš„åšæ³•ï¼Œå½“å®ƒé‡åˆ°ä¸€ä¸ªæ— æ³•è§£ç ä¸ºä»£ç ç‚¹åºåˆ—çš„å­—èŠ‚æ—¶ï¼Œå®ƒå°†å…¶åŸæ ·ä¿ç•™ï¼Œé€šè¿‡å°†å…¶è½¬æ¢ä¸ºä»£ç†å¯¹èŒƒå›´å†…çš„ä»£ç ç‚¹æ¥å®ç°ï¼Œè¿™æ ·å½“éœ€è¦åœ¨æ–‡ä»¶ç³»ç»Ÿä¸Šå†™å…¥å†…å®¹æˆ–è¿›è¡Œå…¶ä»–æ“ä½œæ—¶ï¼Œå°±å¯ä»¥å†æ¬¡è½¬æ¢å›åŸå§‹å­—èŠ‚ã€‚
- en: encoding sometimes you can work around this by telling Python what encoding
    your file systemã€‚ is using sometimes you just have to hope that it works because
    there are some systems thatã€‚ are configured hopelessly but it is a thing that
    has gotten better it is a thing that nowã€‚ mostly reliably works even on those
    badly configured systems which is a big leap forwardã€‚
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼–ç æœ‰æ—¶å¯ä»¥é€šè¿‡å‘Šè¯‰Pythonä½ çš„æ–‡ä»¶ç³»ç»Ÿä½¿ç”¨çš„ç¼–ç æ¥è§„é¿ï¼Œæœ‰æ—¶ä½ åªèƒ½å¸Œæœ›å®ƒèƒ½æ­£å¸¸å·¥ä½œï¼Œå› ä¸ºæœ‰äº›ç³»ç»Ÿçš„é…ç½®æ˜¯ç»æœ›çš„ï¼Œä½†è¿™ç¡®å®æœ‰æ‰€æ”¹å–„ï¼Œç°åœ¨å³ä½¿åœ¨é‚£äº›é…ç½®ä¸è‰¯çš„ç³»ç»Ÿä¸Šä¹ŸåŸºæœ¬å¯é ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„è¿›æ­¥ã€‚
- en: from where it was in the early days of Python 3 of course there are other problems
    you canã€‚
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ä»Python 3æ—©æœŸçš„çŠ¶æ€æ¥çœ‹ï¼Œå½“ç„¶è¿˜æœ‰å…¶ä»–é—®é¢˜ã€‚
- en: '![](img/2a3245dcd9af276985281a539c729f78_25.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_25.png)'
- en: run into we've we've definitely seen examples of normalizing different forms
    that can sometimesã€‚ be a destructive operation depending on what language you're
    working with some languagesã€‚ really rely on the combining and composing features
    of Unicode this example is Koreanã€‚ but it's not the only language that does this
    that initial string is two code pointsã€‚
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç¡®å®è§è¿‡è§„èŒƒåŒ–ä¸åŒå½¢å¼çš„ä¾‹å­ï¼Œè¿™æœ‰æ—¶å¯èƒ½æ˜¯ä¸€ç§ç ´åæ€§æ“ä½œï¼Œå…·ä½“å–å†³äºä½ æ­£åœ¨ä½¿ç”¨çš„è¯­è¨€ã€‚æœ‰äº›è¯­è¨€ç¡®å®ä¾èµ–äºUnicodeçš„ç»„åˆå’Œæ„æˆç‰¹æ€§ï¼Œè¿™ä¸ªä¾‹å­æ˜¯éŸ©è¯­ï¼Œä½†è¿™å¹¶ä¸æ˜¯å”¯ä¸€çš„è¿™æ ·åšçš„è¯­è¨€ã€‚æœ€åˆçš„å­—ç¬¦ä¸²ç”±ä¸¤ä¸ªä»£ç ç‚¹ç»„æˆã€‚
- en: it's two composed characters effectively each one represents one syllable of
    the text andã€‚ each syllable is made up of three individual characters or three
    individual letters thatã€‚ represent the consonants and vowels that go into that
    syllable and performing a decomposingã€‚ normalization can result in that sequence
    of as you see below six different code pointsã€‚
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å®é™…ä¸Šæ˜¯ä¸¤ä¸ªç»„æˆå­—ç¬¦ï¼Œæ¯ä¸ªå­—ç¬¦ä»£è¡¨æ–‡æœ¬çš„ä¸€ä¸ªéŸ³èŠ‚ï¼Œæ¯ä¸ªéŸ³èŠ‚ç”±ä¸‰ä¸ªå•ç‹¬çš„å­—ç¬¦æˆ–ä¸‰ä¸ªå•ç‹¬çš„å­—æ¯ç»„æˆï¼Œè¡¨ç¤ºæ„æˆè¯¥éŸ³èŠ‚çš„è¾…éŸ³å’Œå…ƒéŸ³ã€‚æ‰§è¡Œå»æ„æˆçš„è§„èŒƒåŒ–å¯èƒ½ä¼šå¯¼è‡´å¦‚ä¸‹é¢æ‰€ç¤ºçš„å…­ä¸ªä¸åŒä»£ç ç‚¹çš„åºåˆ—ã€‚
- en: representing the constituent parts of those composed characters those single
    syllable representationsã€‚ and depending on what system you feed them into they
    may render correctly or they mayã€‚ not the terminal application I used to generate
    these examples handled this well and renderedã€‚ both of these strings the same
    way this slide does not so this is something to be aware ofã€‚
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£è¡¨è¿™äº›ç»„æˆå­—ç¬¦çš„æ„æˆéƒ¨åˆ†ï¼Œé‚£äº›å•éŸ³èŠ‚çš„è¡¨ç¤ºå½¢å¼ã€‚è€Œä¸”æ ¹æ®ä½ è¾“å…¥çš„ç³»ç»Ÿï¼Œå®ƒä»¬å¯èƒ½ä¼šæ­£ç¡®æ¸²æŸ“ï¼Œä¹Ÿå¯èƒ½ä¸ä¼šã€‚æˆ‘ç”¨æ¥ç”Ÿæˆè¿™äº›ç¤ºä¾‹çš„ç»ˆç«¯åº”ç”¨ç¨‹åºå¾ˆå¥½åœ°å¤„ç†äº†è¿™äº›ï¼Œå¹¶ä¸”ä»¥ä¸è¿™ä¸ªå¹»ç¯ç‰‡ç›¸åŒçš„æ–¹å¼æ¸²æŸ“äº†è¿™ä¸¤ä¸ªå­—ç¬¦ä¸²ï¼Œä½†è¿™ä¸ªå¹»ç¯ç‰‡æ²¡æœ‰ï¼Œæ‰€ä»¥è¿™æ˜¯éœ€è¦æ³¨æ„çš„äº‹é¡¹ã€‚
- en: and in general combining and composed forms pop up more often than people expect
    a lotã€‚ of emoji for example are made of combining sequences the country flags
    there is a setã€‚ of code points that are called the regional indicator symbols
    and they provide an alphabetã€‚ that lets you spell out two-letter country codes
    and then those render as the flags ofã€‚
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€èˆ¬æ¥è¯´ï¼Œç»„åˆå’Œç»„æˆå½¢å¼å‡ºç°çš„é¢‘ç‡æ¯”äººä»¬é¢„æœŸçš„è¦é«˜ã€‚å¾ˆå¤šè¡¨æƒ…ç¬¦å·ï¼Œä¾‹å¦‚ï¼Œç”±ç»„åˆåºåˆ—ç»„æˆã€‚å›½å®¶æ——å¸œæœ‰ä¸€ç»„ç§°ä¸ºåŒºåŸŸæŒ‡ç¤ºç¬¦ç¬¦å·çš„ä»£ç ç‚¹ï¼Œå®ƒä»¬æä¾›äº†ä¸€ä¸ªå­—æ¯è¡¨ï¼Œå¯ä»¥æ‹¼å†™å‡ºä¸¤ä½æ•°çš„å›½å®¶ä»£ç ï¼Œç„¶åè¿™äº›ä»£ç æ¸²æŸ“æˆå›½å®¶çš„æ——å¸œã€‚
- en: those countries so this is basically the sequence us spelled out in regional
    indicatorã€‚ symbol code points if you wanted something like the flag of Canada
    you would spell CAã€‚ if you wanted the flag of France you would spell FR and that's
    how the flag emoji workã€‚ splitting these down the middle could just destroy the
    meaning because you wouldn't knowã€‚
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å›½å®¶çš„é¡ºåºåŸºæœ¬ä¸Šæ˜¯ç”¨åŒºåŸŸæŒ‡ç¤ºç¬¦ç¬¦å·ä»£ç ç‚¹æ‹¼å†™çš„USã€‚å¦‚æœä½ æƒ³è¦ç±»ä¼¼åŠ æ‹¿å¤§çš„å›½æ——ï¼Œä½ ä¼šæ‹¼å†™CAã€‚å¦‚æœä½ æƒ³è¦æ³•å›½çš„å›½æ——ï¼Œä½ ä¼šæ‹¼å†™FRï¼Œè¿™å°±æ˜¯å›½æ——è¡¨æƒ…ç¬¦å·çš„å·¥ä½œåŸç†ã€‚å°†è¿™äº›ä¸­é—´åˆ†å¼€å¯èƒ½ä¼šæ‘§æ¯å…¶å«ä¹‰ï¼Œå› ä¸ºä½ å°†ä¸çŸ¥é“ã€‚
- en: how to render it anymore the same thing is true of a lot of emoji for people
    for exampleã€‚ this is a family of four people but it's seven different code points
    under the hood and aã€‚ lot of the emoji for people are multi-code point sequences
    either composing groups ofã€‚ people or composing on modifiers to indicate gender
    or skin tone or other attributes andã€‚
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: again splitting in the middle of them can be destructive it can change the meaning
    orã€‚ completely destroy the meaning of a sequence so we need to turn back to that
    concept weã€‚ saw earlier of the graph theme the minimally distinctive unit of meaning
    and unfortunatelyã€‚ Python doesn't directly give you a way to work with graph themes
    in strings but you canã€‚
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: still do it using third party libraries so for example this is a third party
    regularã€‚ expression library called regex you can pip install it and it offers
    a lot more supportã€‚ for Unicode then Python's standard library regex module does
    including things like filteringã€‚ and matching on Unicode properties and most importantly
    for this case it provides a metaã€‚
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: character for matching Unicode graph theme clusters and this is actually defined
    in oneã€‚ of the Unicode specifications it's supposed to be this capital X character
    but it meansã€‚ that we can do things now like count the number of graph themes
    in a string or split on graphã€‚ themes or iterate over graph themes rather than
    risking splitting up a graph theme that'sã€‚
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: made up of multiple code points but even in the Python standard library there
    is stillã€‚ a lot of awareness of Unicode if we go back to for example the regex
    module in the Pythonã€‚ standard library most of us have probably written code like
    this where we're saying ohã€‚ okay I need to match something that you know looks
    like a year so it's a sequence of fourã€‚
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: digits and it's going to be something like 2020 well it turns out Unicode has
    a muchã€‚ broader concept of digit than what speakers of English and Western European
    languagesã€‚ do so that second string for example pulls digit characters from four
    different blocksã€‚ and four different languages that are represented in Unicode
    but it still matches because accordingã€‚
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: to Unicode properties they are all digits and this is an important thing to
    be aware ofã€‚ when you're working with Python in Python 3 where everything is Unicode
    and things areã€‚ mostly Unicode aware that you need to be explicit as the Zen of
    Python says explicitã€‚ is better than implicit but you need to make sure you understand
    what some of these thingsã€‚
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: mean like this digit medic character or the other regex medic characters and
    if what youã€‚ really wanted was only to match digits 0 through 9 from the Latin
    character set you can sayã€‚ that but you do have to be explicit about itã€‚ There
    can also be difficulty with thingsã€‚ like performing string comparisons and working
    with different strings that potentially writeã€‚
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: the same thing different ways and here it can be difficult to give any single
    answer becauseã€‚ the answer is usually context sensitive it depends on what you're
    doingã€‚ So for exampleã€‚ here this is a fairly simple algorithm but it comes from
    one of the Unicode technicalã€‚ reports on security and this is for comparing things
    that might be used as identifiers thingsã€‚
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·çš„äº‹æƒ…ä»¥ä¸åŒçš„æ–¹å¼ï¼Œè¿™é‡Œå¾ˆéš¾ç»™å‡ºå•ä¸€ç­”æ¡ˆï¼Œå› ä¸ºç­”æ¡ˆé€šå¸¸æ˜¯ä¸Šä¸‹æ–‡æ•æ„Ÿçš„ï¼Œè¿™å–å†³äºä½ æ­£åœ¨åšä»€ä¹ˆã€‚ä¾‹å¦‚ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªç›¸å¯¹ç®€å•çš„ç®—æ³•ï¼Œä½†å®ƒæ¥æºäºUnicodeæŠ€æœ¯æŠ¥å‘Šä¸­çš„å®‰å…¨æ€§ï¼Œè¿™ç”¨äºæ¯”è¾ƒå¯èƒ½ç”¨ä½œæ ‡è¯†ç¬¦çš„äº‹ç‰©ã€‚
- en: like maybe variable names in a programming language or usernames in an account
    systemã€‚ and this gives you a way to compare them in a case insensitive way and
    figure out whichã€‚ ones should be considered equivalent and which ones should notã€‚
    There are other ways to normalizeã€‚ and prepare strings for comparison and for
    use and it really does depend on your use caseã€‚
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ç¼–ç¨‹è¯­è¨€ä¸­çš„å˜é‡åæˆ–å¸æˆ·ç³»ç»Ÿä¸­çš„ç”¨æˆ·åï¼Œè¿™ä¸ºä½ æä¾›äº†ä¸€ç§æ— è§†å¤§å°å†™åœ°æ¯”è¾ƒå®ƒä»¬çš„æ–¹æ³•ï¼Œå¹¶æ‰¾å‡ºå“ªäº›åº”è¯¥è¢«è§†ä¸ºç­‰ä»·ï¼Œå“ªäº›ä¸åº”è¯¥ã€‚è¿˜æœ‰å…¶ä»–æ–¹æ³•æ¥è§„èŒƒåŒ–å¹¶å‡†å¤‡å­—ç¬¦ä¸²è¿›è¡Œæ¯”è¾ƒå’Œä½¿ç”¨ï¼Œç¡®å®å–å†³äºä½ çš„ç”¨ä¾‹ã€‚
- en: Python supports quite a few of them for example if you are working with domain
    names which canã€‚ be internationalized now there are modules in the standard library
    that support this theã€‚ encoding codeingsã€‚idna module the puny code codec let you
    work with these and transformã€‚ internationalized domain names into an ASCII compatible
    form that's safe to transmit throughã€‚
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Pythonæ”¯æŒç›¸å½“å¤šçš„åŠŸèƒ½ï¼Œä¾‹å¦‚ï¼Œå¦‚æœä½ åœ¨å¤„ç†å¯ä»¥å›½é™…åŒ–çš„åŸŸåï¼Œç°åœ¨æ ‡å‡†åº“ä¸­æœ‰æ”¯æŒè¿™ä¸ªçš„æ¨¡å—ï¼Œç¼–ç ä»£ç çš„idnaæ¨¡å—å’Œpunycodeç¼–è§£ç å™¨è®©ä½ å¯ä»¥å¤„ç†è¿™äº›ï¼Œå¹¶å°†å›½é™…åŒ–åŸŸåè½¬æ¢ä¸ºå®‰å…¨çš„ASCIIå…¼å®¹å½¢å¼ä»¥ä¾¿ä¼ è¾“ã€‚
- en: a lot of systems that maybe aren't aware of internationalized domain namesã€‚
    There areã€‚ also even trickier things that you can get by digging into third-party
    modulesã€‚ For exampleã€‚ this is something that comes and goes where people will
    try to fool you by writing outã€‚ a domain name or maybe an email address or a username
    or some other identifier using aã€‚
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¤šç³»ç»Ÿå¯èƒ½ä¸å¤ªäº†è§£å›½é™…åŒ–åŸŸåã€‚è¿˜æœ‰æ›´æ£˜æ‰‹çš„äº‹æƒ…ï¼Œå¯ä»¥é€šè¿‡æ·±å…¥æŒ–æ˜ç¬¬ä¸‰æ–¹æ¨¡å—è·å–ã€‚ä¾‹å¦‚ï¼Œè¿™ç§æƒ…å†µæ—¶æœ‰å‘ç”Ÿï¼Œäººä»¬ä¼šè¯•å›¾é€šè¿‡ä½¿ç”¨å¤šä¸ªè„šæœ¬çš„ä»£ç ç‚¹æ¥æ„šå¼„ä½ ï¼Œå†™å‡ºåŸŸåã€ç”µå­é‚®ä»¶åœ°å€ã€ç”¨æˆ·åæˆ–å…¶ä»–æ ‡è¯†ç¬¦ã€‚
- en: mix of scripts where some of the characters look like each other but aren't
    actually theã€‚ same and Unicode actually includes a database for this called the
    visually confusing charactersã€‚ file and there's a third-party module that you
    can go download that has this wonderfulã€‚ function and it called is dangerousã€‚
    I love that name that tells you when a string containsã€‚
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ¶‰åŠåˆ°æ··åˆè„šæœ¬ï¼Œå…¶ä¸­ä¸€äº›å­—ç¬¦çœ‹èµ·æ¥ç›¸ä¼¼ä½†å®é™…ä¸Šå¹¶ä¸ç›¸åŒï¼Œè€ŒUnicodeå®é™…ä¸ŠåŒ…å«ä¸€ä¸ªç§°ä¸ºè§†è§‰æ··æ·†å­—ç¬¦æ–‡ä»¶çš„æ•°æ®åº“ï¼Œè¿˜æœ‰ä¸€ä¸ªç¬¬ä¸‰æ–¹æ¨¡å—å¯ä»¥ä¸‹è½½ï¼Œå…·æœ‰è¿™ä¸ªå¥‡å¦™çš„åŠŸèƒ½ï¼Œå®ƒè¢«ç§°ä¸ºis
    dangerousã€‚æˆ‘å–œæ¬¢è¿™ä¸ªåå­—ï¼Œå®ƒèƒ½å‘Šè¯‰ä½ å­—ç¬¦ä¸²ä¸­æ˜¯å¦åŒ…å«ã€‚
- en: code points from multiple scripts and some of them appear in that visually confusingã€‚
    characters file some of them are confusable characters so you can notice when
    somebody'sã€‚ trying to do something dangerous and that module also includes a lot
    of other information thatã€‚ you can access so you can ask it to show you a list
    of what are the confusable charactersã€‚
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ä¸€äº›å‡ºç°åœ¨è§†è§‰æ··æ·†å­—ç¬¦æ–‡ä»¶ä¸­ï¼Œä¸€äº›æ˜¯å¯æ··æ·†å­—ç¬¦ï¼Œæ‰€ä»¥ä½ å¯ä»¥æ³¨æ„åˆ°æœ‰äººè¯•å›¾åšä¸€äº›å±é™©çš„äº‹æƒ…ï¼Œè€Œè¯¥æ¨¡å—è¿˜åŒ…å«å¤§é‡å…¶ä»–ä¿¡æ¯ï¼Œä½ å¯ä»¥è¯·æ±‚å®ƒå±•ç¤ºå¯æ··æ·†å­—ç¬¦çš„åˆ—è¡¨ã€‚
- en: what was it that set this off what were the script properties that were being
    used inã€‚ this string that were being mixed together and there's really a whole
    wide world of thingsã€‚
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯ä»€ä¹ˆå¼•å‘äº†è¿™ä¸ªé—®é¢˜ï¼Œè¿™ä¸ªå­—ç¬¦ä¸²ä¸­æ··åˆä½¿ç”¨çš„è„šæœ¬å±æ€§æ˜¯ä»€ä¹ˆï¼Œè¿™é‡Œå®é™…ä¸Šæœ‰å¾ˆå¤šå†…å®¹ã€‚
- en: '![](img/2a3245dcd9af276985281a539c729f78_27.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_27.png)'
- en: out there but hopefully at this point you've got a handle on the core ideas
    of what goesã€‚ into Unicode what it is why it's complex and where that complexity
    comes from so you canã€‚ start thinking about that complexity in a productive way
    start anticipating where youã€‚ may need to do extra work where you may need to
    worry about something and how you can writeã€‚
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: å¤–é¢çš„å†…å®¹ï¼Œä½†å¸Œæœ›æ­¤æ—¶ä½ å·²ç»æŒæ¡äº†Unicodeçš„æ ¸å¿ƒç†å¿µï¼Œå®ƒæ˜¯ä»€ä¹ˆã€ä¸ºä»€ä¹ˆå¤æ‚ä»¥åŠè¿™ç§å¤æ‚æ€§æ¥æºäºå“ªé‡Œï¼Œè¿™æ ·ä½ å°±å¯ä»¥å¼€å§‹ä»¥å¯Œæœ‰æˆæ•ˆçš„æ–¹å¼æ€è€ƒè¿™ç§å¤æ‚æ€§ï¼Œå¼€å§‹é¢„è§ä½•æ—¶å¯èƒ½éœ€è¦é¢å¤–çš„å·¥ä½œï¼Œä½•æ—¶å¯èƒ½éœ€è¦æ‹…å¿§ï¼Œä»¥åŠå¦‚ä½•ç¼–å†™ã€‚
- en: better more effective code and feel more confident about how you're using Unicode
    and of courseã€‚
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¥½ã€æ›´æœ‰æ•ˆçš„ä»£ç è®©ä½ å¯¹å¦‚ä½•ä½¿ç”¨Unicodeæ›´æœ‰ä¿¡å¿ƒï¼Œå½“ç„¶ã€‚
- en: '![](img/2a3245dcd9af276985281a539c729f78_29.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_29.png)'
- en: if you have any questions unfortunately this is an online presentation because
    PyCon hadã€‚ to be canceled this year but I'm happy to have people reach out and
    ask me questionsã€‚ I also keep a blog where I regularly rant about all sorts of
    things including Unicodeã€‚ which has its own category there and finally I want
    to take a minute to just thank theã€‚
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œä¸å¹¸çš„æ˜¯è¿™æ˜¯ä¸€åœºåœ¨çº¿æ¼”è®²ï¼Œå› ä¸ºä»Šå¹´çš„PyConä¸å¾—ä¸å–æ¶ˆï¼Œä½†æˆ‘å¾ˆé«˜å…´æœ‰äººèƒ½è”ç³»æˆ‘å¹¶é—®æˆ‘é—®é¢˜ã€‚æˆ‘è¿˜ä¿æŒä¸€ä¸ªåšå®¢ï¼Œå®šæœŸåæ§½å„ç§äº‹æƒ…ï¼ŒåŒ…æ‹¬Unicodeï¼Œé‚£é‡Œæœ‰è‡ªå·±ç‹¬ç«‹çš„åˆ†ç±»ï¼Œæœ€åæˆ‘æƒ³èŠ±ä¸€ç‚¹æ—¶é—´æ„Ÿè°¢ã€‚
- en: PyCon organizers and the PSF because they were really put in an impossible situation
    thisã€‚ year and as sad as it is that the in-person version of PyCon 2020 had to
    be canceled itã€‚ really is incredible the way that they reacted and responded and
    were able to put togetherã€‚ this online track of talks as quickly as they did and
    as successfully as they did so if you'reã€‚
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: PyConçš„ç»„ç»‡è€…å’ŒPSFï¼Œå› ä¸ºä»–ä»¬ä»Šå¹´é¢ä¸´äº†ä¸€ä¸ªä¸å¯èƒ½çš„å±€é¢ã€‚å°½ç®¡2020å¹´PyConçš„çº¿ä¸‹ç‰ˆæœ¬è¢«å–æ¶ˆæ˜¯ä»¤äººæ‚²ä¼¤çš„ï¼Œä½†ä»–ä»¬ååº”å’Œåº”å¯¹çš„æ–¹å¼ï¼Œä»¥åŠèƒ½å¤Ÿå¦‚æ­¤è¿…é€Ÿè€ŒæˆåŠŸåœ°ç»„ç»‡è¿™æ¡åœ¨çº¿è®²åº§çš„æ–¹å¼ï¼ŒçœŸçš„ä»¤äººéš¾ä»¥ç½®ä¿¡ï¼Œæ‰€ä»¥å¦‚æœä½ æ­£åœ¨ã€‚
- en: watching this please be thankful for the PSF for the PyCon organizers and for
    all theã€‚ work they put in to putting this online and pulling off a remote PyCon
    2020 on such shortã€‚ notice and under the worst possible conditionsã€‚ In the meantime
    stay safe hopefully I will see you at a PyCon in person sometime in theã€‚ futureã€‚
    Thank youã€‚
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚çœ‹è¿™ä¸ªçš„äººï¼Œè¯·æ„Ÿè°¢PSFã€PyConçš„ç»„ç»‡è€…ä»¥åŠä»–ä»¬ä¸ºåœ¨çº¿ä¸¾åŠ2020å¹´è¿œç¨‹PyConæ‰€ä»˜å‡ºçš„åŠªåŠ›ï¼Œè¿™ä¸€åˆ‡éƒ½æ˜¯åœ¨å¦‚æ­¤çŸ­çš„æ—¶é—´å’Œæœ€ç³Ÿç³•çš„æ¡ä»¶ä¸‹å®Œæˆçš„ã€‚ä¸æ­¤åŒæ—¶ï¼Œä¿æŒå®‰å…¨ï¼Œå¸Œæœ›å°†æ¥èƒ½åœ¨æŸä¸ªPyConä¸Šè§åˆ°ä½ ã€‚è°¢è°¢ã€‚
- en: '![](img/2a3245dcd9af276985281a539c729f78_31.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_31.png)'
- en: so much for watchingã€‚ for watchingã€‚ the PSF for watchingã€‚ the PSF for watchingã€‚
    [BLANK_AUDIO]ã€‚
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢è§‚çœ‹ã€‚æ„Ÿè°¢è§‚çœ‹ã€‚æ„Ÿè°¢PSFçš„è§‚çœ‹ã€‚æ„Ÿè°¢PSFçš„è§‚çœ‹ã€‚[ç©ºç™½éŸ³é¢‘]ã€‚
- en: '![](img/2a3245dcd9af276985281a539c729f78_33.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a3245dcd9af276985281a539c729f78_33.png)'
